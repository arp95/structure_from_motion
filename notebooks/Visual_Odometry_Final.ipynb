{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.optimize import leastsq\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from ReadCameraModel import *\n",
    "from UndistortImage import *\n",
    "%matplotlib inline\n",
    "\n",
    "# Data Preparation\n",
    "\n",
    "camera_model = glob.glob('C:\\\\Users\\\\shant\\\\dataset\\\\model\\\\')\n",
    "data_files = glob.glob('C:\\\\Users\\\\shant\\\\dataset\\\\stereo\\\\centre\\\\')\n",
    "\n",
    "def intrinsic_matrix_undistorted_image(images,model_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    model_path: The path to the model files\n",
    "    images: The input image\n",
    "    \n",
    "    Outputs:\n",
    "    k_matrix: The intrinsic parameters\n",
    "    undistorted_image: The undistorted image\n",
    "    \"\"\"\n",
    "    image = cv2.imread(images,0)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BayerBG2BGR)\n",
    "    \n",
    "    fx, fy, cx, cy, G_camera_image, LUT = ReadCameraModel(model_path)\n",
    "    k_matrix = np.zeros((3,3))\n",
    "    k_matrix[0,0] = fx\n",
    "    k_matrix[0,2] = cx\n",
    "    k_matrix[1,1] = fy\n",
    "    k_matrix[1,2] = cy\n",
    "    k_matrix[2,2] = 1\n",
    "    \n",
    "    undistorted_image = UndistortImage(image, LUT)\n",
    "    \n",
    "    return (undistorted_image, k_matrix)\n",
    "\n",
    "# Estimating the Fundamental and Essential Matrix\n",
    "\n",
    "def FundamentalMatrix(input_points, output_correspondence, scaling):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    input_points: This is a Nx2 Matrix of (x,y) points\n",
    "    output_correspondance: This is a Nx2 Matrix of (x',y') points\n",
    "    scaling: The maximum of the input images width and height\n",
    "    \n",
    "    \"\"\"\n",
    "    # Normalize the input coordinates with the scaling factor\n",
    "    \n",
    "    pts1 = input_points / scaling\n",
    "    pts2 = output_correspondence / scaling\n",
    "    \n",
    "    # List of Fundamental Matrix\n",
    "    F_list = []\n",
    "    \n",
    "    # Transformation matrix for unnormalizing the fundamental matrix\n",
    "    T = np.array([[1/scaling,0,0],[0,1/scaling,0],[0,0,1]])\n",
    "    \n",
    "    # Construct the A matrix \n",
    "    first_row_A = np.array([[pts1[:,0][0]*pts2[:,0][0], pts1[:,0][0]*pts2[:,1][0], pts1[:,0][0], pts1[:,1][0]*pts2[:,0][0], pts1[:,1][0]*pts2[:,1][0], pts1[:,1][0], pts2[:,0][0], pts2[:,1][0], 1]])\n",
    "    second_row_A = np.array([[pts1[:,0][1]*pts2[:,0][1], pts1[:,0][1]*pts2[:,1][1], pts1[:,0][1], pts1[:,1][1]*pts2[:,0][1], pts1[:,1][1]*pts2[:,1][1], pts1[:,1][1], pts2[:,0][1], pts2[:,1][1], 1]])\n",
    "    third_row_A = np.array([[pts1[:,0][2]*pts2[:,0][2], pts1[:,0][2]*pts2[:,1][2], pts1[:,0][2], pts1[:,1][2]*pts2[:,0][2], pts1[:,1][2]*pts2[:,1][2], pts1[:,1][2], pts2[:,0][2], pts2[:,1][2], 1]]) \n",
    "    fourth_row_A = np.array([[pts1[:,0][3]*pts2[:,0][3], pts1[:,0][3]*pts2[:,1][3], pts1[:,0][3], pts1[:,1][3]*pts2[:,0][3], pts1[:,1][3]*pts2[:,1][3], pts1[:,1][3], pts2[:,0][3], pts2[:,1][3], 1]])\n",
    "    fifth_row_A = np.array([[pts1[:,0][4]*pts2[:,0][4], pts1[:,0][4]*pts2[:,1][4], pts1[:,0][4], pts1[:,1][4]*pts2[:,0][4], pts1[:,1][4]*pts2[:,1][4], pts1[:,1][4], pts2[:,0][4], pts2[:,1][4], 1]])\n",
    "    sixth_row_A = np.array([[pts1[:,0][5]*pts2[:,0][5], pts1[:,0][5]*pts2[:,1][5], pts1[:,0][5], pts1[:,1][5]*pts2[:,0][5], pts1[:,1][5]*pts2[:,1][5], pts1[:,1][5], pts2[:,0][5], pts2[:,1][5], 1]])\n",
    "    seventh_row_A = np.array([[pts1[:,0][6]*pts2[:,0][6], pts1[:,0][6]*pts2[:,1][6], pts1[:,0][6], pts1[:,1][6]*pts2[:,0][6], pts1[:,1][6]*pts2[:,1][6], pts1[:,1][6], pts2[:,0][6], pts2[:,1][6], 1]]) \n",
    "    eighth_row_A = np.array([[pts1[:,0][7]*pts2[:,0][7], pts1[:,0][7]*pts2[:,1][7], pts1[:,0][7], pts1[:,1][7]*pts2[:,0][7], pts1[:,1][7]*pts2[:,1][7], pts1[:,1][7], pts2[:,0][7], pts2[:,1][7], 1]])\n",
    "    \n",
    "    # Stack the rows to create the A matrix\n",
    "    A = np.vstack((first_row_A,second_row_A,third_row_A,fourth_row_A,fifth_row_A,sixth_row_A,seventh_row_A,eighth_row_A,np.ones(9)))\n",
    "    # Singular Value Decomposition\n",
    "    U, S, Vh = np.linalg.svd(A)\n",
    "    V = Vh.T\n",
    "    \n",
    "    # Constructing the fundamental matrix by taking the last column of the V matrix as it corresponds to the nullspace eigenvector\n",
    "    fundamental_matrix = V[:,-1]\n",
    "    fundamental_matrix = fundamental_matrix.reshape(3,3)\n",
    "    \n",
    "    # Enforcing Rank 2 constraint\n",
    "    U, sigma, Vh = np.linalg.svd(fundamental_matrix)\n",
    "    sigma[2] = 0\n",
    "    fundamental_matrix = np.matmul(U, np.matmul(np.diag(sigma), Vh))\n",
    "    \n",
    "    # Unnormalize the fundmental matrix\n",
    "    fundamental_matrix = np.matmul(np.matmul(T.T, fundamental_matrix), T)\n",
    "    \n",
    "    F_list.append(fundamental_matrix)\n",
    "    return F_list\n",
    "    \n",
    "def get_keypoints(image1, image2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    image1: left image\n",
    "    image2: right image\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    ptsLeft: point correspondences for left image\n",
    "    ptsRight: point correspondences for right image\n",
    "    \"\"\"\n",
    "\n",
    "    # use sift keypoint to get the points\n",
    "    sift = cv2.ORB_create()\n",
    "    kp1, des1 = sift.detectAndCompute(image1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(image2, None)\n",
    "    des1 = np.asarray(des1, np.float32)\n",
    "    des2 = np.asarray(des2, np.float32)\n",
    "    flann = cv2.FlannBasedMatcher(dict(algorithm = 0, trees = 5), dict(checks = 50))\n",
    "    matches = flann.knnMatch(des1, des2, k = 2)\n",
    "    good = []\n",
    "    ptsLeft = []\n",
    "    ptsRight = []\n",
    "\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            good.append(m)\n",
    "            ptsRight.append(kp2[m.trainIdx].pt)\n",
    "            ptsLeft.append(kp1[m.queryIdx].pt)\n",
    "\n",
    "    ptsLeft = np.int32(ptsLeft)\n",
    "    ptsRight = np.int32(ptsRight)\n",
    "    return (ptsLeft, ptsRight)\n",
    "\n",
    "def FundamentalMatrixRansac(input_points, output_correspondence, scaling):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    input_points: This is a randomly sampled input point correspondence\n",
    "    output_correspondance: This is the output point correspondence\n",
    "    \n",
    "    Outputs:\n",
    "    fundamental_matrix: The refined fundamental matrix after performing RANSAC\n",
    "    \"\"\"\n",
    "    # Convert the correspondences into homogenous coordinates\n",
    "    pts1 = np.hstack(input_points, np.ones(input_points.shape[0],1))\n",
    "    pts2 = np.hstack(output_correspondence, np.ones(output_correspondence.shape[0], 1))\n",
    "    \n",
    "    # Number of iterations\n",
    "    iterations = 1000\n",
    "    \n",
    "    # The threshold error\n",
    "    epsilon = 0.01\n",
    "    \n",
    "    # The indices with value less than the error\n",
    "    best_indices = None\n",
    "    \n",
    "    # Best Fundamental Matrix\n",
    "    best_fundamental_matrix = None\n",
    "    \n",
    "    # Best Inliers\n",
    "    best_inliers = 0\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        rand_index = np.random.choice(input_points.shape[0], 8, False)\n",
    "        F = FundamentalMatrix(input_points[rand_index], output_correspondence[rand_index],scaling)\n",
    "        \n",
    "        for fundamental_matrix in F:\n",
    "            \n",
    "            # Print a List of indices\n",
    "            indices = np.where(np.abs(np.matmul(pts2, np.matmul(fundamental_matrix, pts.T))).diagonal() < epsilon)[0]\n",
    "            \n",
    "            if len(indices) > best_inliers:\n",
    "                \n",
    "                best_fundamental_matrix = fundamental_matrix\n",
    "                best_indices = indices\n",
    "                best_inliers = len(indices)\n",
    "\n",
    "# Compute the Essential Matrix\n",
    "def EssentialMatrix(fundamental_matrix, calibration_matrix):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    fundamental_matrix: The fundamental matrix that gives the epipolar line on which an input point must lie\n",
    "    calibration_matrix: The K matrix responsible for projecting an object in camera coordinates to the image coordinate system\n",
    "    \n",
    "    Ouput:\n",
    "    essential_matrix: The essential matrix giving the relation between the 2 image points\n",
    "    \"\"\"\n",
    "    essential_matrix = np.matmul(calibration_matrix.T, np.matmul(fundamental_matrix,calibration_matrix))\n",
    "    U, sigma, Vh = np.linalg.svd(essential_matrix)\n",
    "    \n",
    "    sigma[0] = 1\n",
    "    sigma[1] = 1\n",
    "    sigma[2] = 0\n",
    "    \n",
    "    essential_matrix = np.matmul(U, np.matmul(np.diag(sigma), Vh))\n",
    "    \n",
    "    return essential_matrix\n",
    "\n",
    "# Get the Camera Poses(translation and rotation matrices)\n",
    "def ExtractCameraPose(essential_matrix):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    essential_matrix: The Essential Matrix\n",
    "    \n",
    "    Outputs:\n",
    "    Camera Poses\n",
    "    \"\"\"\n",
    "    \n",
    "    W = np.array([[0,-1,0],[1,0,0],[0,0,1]])\n",
    "    \n",
    "    # Perform the Singular Value Decomposition of the Essential Matrix\n",
    "    U, sigma, Vh = np.linalg.svd(essential_matrix)\n",
    "    \n",
    "    # Defining the 4 Camera Poses (c1,r1), (c2,r2), (c3,r3), (c4,r4)\n",
    "    c1 = U[:,2]\n",
    "    c2 = -U[:,2]\n",
    "    c3 = U[:,2]\n",
    "    c4 = -U[:,2]\n",
    "    r1 = np.dot(U, np.dot(W, Vh))\n",
    "    r2 = np.dot(U, np.dot(W, Vh))\n",
    "    r3 = np.dot(U, np.dot(np.transpose(W), Vh))\n",
    "    r4 = np.dot(U, np.dot(np.transpose(W), Vh))\n",
    "    \n",
    "    if np.linalg.det(r1) < 0:\n",
    "        c1 = -c1\n",
    "        r1 = -r1\n",
    "    if np.linalg.det(r2) < 0:\n",
    "        c2 = -c2\n",
    "        r2 = -r2\n",
    "    if np.linalg.det(r3) < 0:\n",
    "        c3 = -c3\n",
    "        r3 = -r3\n",
    "    if np.linalg.det(r4) < 0:\n",
    "        c4 = -c4\n",
    "        r4 = -r4\n",
    "    \n",
    "    # Reshape the translational matrices from 1x3 --> 3x1\n",
    "    c1 = c1.reshape(-1,1)\n",
    "    c2 = c2.reshape(-1,1)\n",
    "    c3 = c3.reshape(-1,1)\n",
    "    c4 = c4.reshape(-1,1)\n",
    "    \n",
    "    return [np.array(c1), np.array(c2), np.array(c3), np.array(c4)],[np.array(r1), np.array(r2), np.array(r3), np.array(r4)]\n",
    "\n",
    "# Triangulation Check for Cheirality \n",
    "def LinearTriangulation(K, C1, R1, C2, R2, pts1, pts2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    K: Camera Calibration Matrix\n",
    "    C1: The camera center for the first camera (3x1)\n",
    "    C2: The camera center for the second camera (3x1)\n",
    "    R1: The rotation matrix for the first camera (3x3)\n",
    "    R2: The rotation matrix for the second camera (3x3)\n",
    "    pts1: The points in left image whose correspondance needs to be found in the right image. (Nx2)\n",
    "    pts2: The corresponding points in the right image (Nx2)\n",
    "    \n",
    "    Outputs:\n",
    "    P: x, y, z world coordinates (Nx3)/ Triangulated points\n",
    "    reprojection_error: The reprojection error from the world frame to the image frame\n",
    "    \"\"\"\n",
    "    \n",
    "    camera_pose1 = np.dot(np.dot(K,R1), np.concatenate((np.eye(3), -C1), axis = 1))\n",
    "    camera_pose2 = np.dot(np.dot(K,R2), np.concatenate((np.eye(3), -C2), axis = 1))\n",
    "    \n",
    "    P = []\n",
    "    reprojection_error = 0\n",
    "    \n",
    "    # Constructing the A matrix\n",
    "    for i in range(pts1.shape[0]):\n",
    "        \n",
    "        A =  [pts1[i, 0] * camera_pose1[2, :] - camera_pose1[0, :],\n",
    "              pts1[i, 1] * camera_pose1[2, :] - camera_pose1[1, :],\n",
    "              pts2[i, 0] * camera_pose2[2, :] - camera_pose2[0, :],\n",
    "              pts2[i, 1] * camera_pose2[2, :] - camera_pose2[1, :]]\n",
    "        \n",
    "        \n",
    "        # Perform the singular value decomposition of the A matrix\n",
    "        U, sigma, Vh = np.linalg.svd(A)\n",
    "        \n",
    "        # Extract the last row corresponding the nullspace of the linear equation\n",
    "        p = Vh[-1,:]\n",
    "        \n",
    "        # Convert to homogenous coordinates\n",
    "        w = p/p[3]\n",
    "        \n",
    "        # X,Y,Z co-ordinates in the world frame\n",
    "        P.append(w)\n",
    "        \n",
    "        # Checking the Reprojection Error\n",
    "        projection1 = np.dot(camera_pose1, w)\n",
    "        projection2 = np.dot(camera_pose2, w)\n",
    "        \n",
    "        # Calculating the Reprojection error\n",
    "        # Computing the eucledian distance between the projected image and the object in the world frame\n",
    "        reprojection_error += np.linalg.norm(projection1[:2]/projection1[-1] - pts1[i])**2 + np.linalg.norm(projection2[:2]/projection2[-1] - pts2[i])**2\n",
    "        \n",
    "    return np.asarray(P), reprojection_error\n",
    "\n",
    "def NonLinearTriangulationError(K, C1, R1, C2, R2, pts1, pts2, triangulated_points):\n",
    "        \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    K: The camera calibration matrix\n",
    "    C1 and R1: The first camera pose\n",
    "    C2 and R2: The second camera pose\n",
    "    pts1 and pts2: The Nx2 point correspondence\n",
    "    X0: The triangulated points (Nx4)\n",
    "    \"\"\"\n",
    "    # The camera poses/ Projection Matrices\n",
    "    P1 = np.dot(np.dot(K,R1), np.concatenate((np.eye(3), -C1), axis = 1))\n",
    "    P2 = np.dot(np.dot(K,R2), np.concatenate((np.eye(3), -C2), axis = 1))\n",
    "    \n",
    "    # The Error terms\n",
    "    u_reprojection1 = np.matmul(P1[0].reshape(1,4), triangulated_points) / np.matmul(P1[2].reshape(1,4), triangulated_points)\n",
    "    v_reprojection1 = np.matmul(P1[1].reshape(1,4), triangulated_points) / np.matmul(P1[2].reshape(1,4), triangulated_points)\n",
    "    u_reprojection2 = np.matmul(P2[0].reshape(1,4), triangulated_points) / np.matmul(P2[2].reshape(1,4), triangulated_points)\n",
    "    v_reprojection2 = np.matmul(P2[1].reshape(1,4), triangulated_points) / np.matmul(P2[2].reshape(1,4), triangulated_points)\n",
    "    \n",
    "    diff1 = (pts1.T[0,:].reshape(1,4) - u_reprojection1)**2\n",
    "    diff2 = (pts1.T[1,:].reshape(1,4) - v_reprojection1)**2\n",
    "    diff3 = (pts2.T[0,:].reshape(1,4) - u_reprojection2)**2\n",
    "    diff4 = (pts2.T[1,:].reshape(1,4) - v_reprojection2)**2\n",
    "    \n",
    "    reprojection_error = diff1 + diff2 + diff3 + diff4\n",
    "    return reprojection_error\n",
    "    \n",
    "# Non Linear Triangulation\n",
    "def NonLinearTriangulation(K, C1, R1, C2, R2, pts1, pts2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    K: The camera calibration matrix\n",
    "    C1 and R1: The first camera pose\n",
    "    C2 and R2: The second camera pose\n",
    "    pts1 and pts2: The Nx2 point correspondence\n",
    "    \n",
    "    Outputs:\n",
    "    X: Nx3 Matrix that represents the triangulated points\n",
    "    \"\"\"\n",
    "    # Get the Triangulated points array\n",
    "    triangulated_points, reprojection_error = LinearTriangulation(K,C1,R1,C2,R2,pts1,pts2)\n",
    "    \n",
    "    # Reprojection Error Minimization using Levenberg-Marquardt Method\n",
    "    args = (K, C1, R1, C2, R2, pts1, pts2)\n",
    "    refined_triangulated, success = leastsq(NonLinearTriangulationError,triangulated_points,args = args)\n",
    "    \n",
    "    return refined_triangulated\n",
    "\n",
    "# Check whether the point is infront of the camera pose or not\n",
    "def DisambiguateCameraPose(Cset, Rset, Xset):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    Cset: 4 Camera Rotation Configurations\n",
    "    Rset: 4 Camera rotation configurations\n",
    "    Xset: 4 set of traingulated camera points\n",
    "    \n",
    "    Output:\n",
    "    C,R: The best Camera Pose\n",
    "    \n",
    "    \"\"\"\n",
    "    best = 0\n",
    "    \n",
    "    for i in range(4):\n",
    "        \n",
    "        # Loop through each correspondence\n",
    "        counter = 0\n",
    "        for j in range(len(Xset[i])):\n",
    "            \n",
    "            # Cheirality Condition\n",
    "            if(Rset[i][2,:]*(Xset[i][j,:] - Cset[i]) > 0):\n",
    "                \n",
    "                counter = counter + 1\n",
    "                \n",
    "        if counter > best:\n",
    "            \n",
    "            C = Cset[i]\n",
    "            R = Rset[i]\n",
    "            X0 = Xset[i]\n",
    "            best = counter\n",
    "    \n",
    "    return C, R, X0\n",
    "\n",
    "def LinearPnp(X,x,K):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    X: This is an Nx4 Homogenous Matrix whose row gives correspondence with the 2D Image\n",
    "    x: This is an Nx2 Matrix whose row gives correspondence with the 3D Image\n",
    "    K: The Camera Calibration Matrix\n",
    "    \n",
    "    Outputs:\n",
    "    C, R: The Camera Pose\n",
    "    \"\"\"\n",
    "    # Convert the 2D Correspondence to the optical world\n",
    "    x = np.dot(np.linalg.inv(K), x.T)\n",
    "    \n",
    "    # Convert the 2d correspondence to homogenous coordinates\n",
    "    x = np.concatenate((pts1,np.ones((pts1.shape[0],1))), axis=1)\n",
    "    \n",
    "    # Construct the A Matrix\n",
    "    \n",
    "    A = []\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        \n",
    "        X_thilda = X[i,:]\n",
    "        zeros = np.zeros((1,4))\n",
    "        2d_correspondence = x[i,:]\n",
    "        A_matrix = np.array([[zeros, -X_thilda, 2d_correspondence[1]*X_thilda],[X_thilda, zeros, -2d_correspondence[0]*X_thilda],[-2d_correspondence[1]*X_thilda, 2d_correspondence[0]*X_thilda, zeros]])\n",
    "        A.append(A_matrix)\n",
    "        \n",
    "    # Stack the matrices to make an Nx12 Dimensional matrix\n",
    "    A = np.vstack(A)\n",
    "    \n",
    "    # Perform the Singular Value Decomposition\n",
    "    U, sigma, Vh = np.linalg.svd(A)\n",
    "    \n",
    "    # The last row of Vh corresponds to the solution\n",
    "    # We reshape the solution into a 3x4 matrix\n",
    "    P = Vh[-1,:].reshape(3,4)\n",
    "    \n",
    "    # The rotation Matrix is \n",
    "    R = P[:,:3]\n",
    "    \n",
    "    # The translation matrix is \n",
    "    t = P[:,3:]\n",
    "    \n",
    "    # Perform SVD as the least squares solution doesnot enforce orthogonality\n",
    "    U, sigma, Vh = np.linalg.svd(R)\n",
    "    \n",
    "    # Enforce Orthogonality\n",
    "    R = np.dot(U, Vh)\n",
    "    \n",
    "    # Camera Center \n",
    "    C = np.dot(-np.linalg.inv(R), t)\n",
    "    \n",
    "    # Some Constraints\n",
    "    if np.linalg.det(R) < 0:\n",
    "        \n",
    "        R = -R\n",
    "        C = -C\n",
    "        \n",
    "    return C, R\n",
    "    \n",
    "def NonLinearPnp(X,x,K,C,R):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    X: This is an Nx3 Matrix whose row gives correspondence with the 2D Image\n",
    "    x: This is an Nx2 Matrix whose row gives correspondence with the 3D Image\n",
    "    C, R: The Camera Pose\n",
    "    \n",
    "    Output:\n",
    "    C, R: The Camera Pose\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "C1 = np.array([[1],[2],[3]])\n",
    "R1 = np.array([[1,2,0],[0,-1,0],[0,0,1]])\n",
    "C2 = np.array([[4],[5],[6]])\n",
    "R2 = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "pts1 = np.array([[1,2],[3,4],[5,6],[7,8]])\n",
    "pts2 = np.array([[9,0],[11,12],[13,14],[15,16]])\n",
    "triangulated_points, error = LinearTriangulation(K,C1,R1,C2,R2,pts1,pts2)\n",
    "#NonLinearTriangulation(K,C1,R1,C2,R2,pts1,pts2)\n",
    "#triangulated_points\n",
    "pts1[0,:]\n",
    "#np.dot(np.dot(K,R1), np.concatenate((np.eye(3), -C1), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [5],\n",
       "       [6]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1],[2],[3],[4]])\n",
    "K = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "C1 = np.array([[1],[2],[3]])\n",
    "R1 = np.array([[1,2,0],[0,-1,0],[0,0,1]])\n",
    "C2 = np.array([[4],[5],[6]])\n",
    "R2 = np.array([[1,2,3,4],[4,5,6,5],[7,8,9,6]])\n",
    "pts1 = np.array([[1,2],[3,4],[5,6],[7,8]])\n",
    "pts2 = np.array([[9,0],[11,12],[13,14],[15,16]])\n",
    "\n",
    "#np.concatenate((pts1,np.ones((pts1.shape[0],1))), axis=1)\n",
    "#R2[:,:3]\n",
    "R2[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 169.45325806, -174.75550062,  -45.91440416,   -6.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = np.dot(np.dot(K,R1), np.concatenate((np.eye(3), -C1), axis = 1))\n",
    "np.matmul(P[0,:].reshape(1,4),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) c:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0xe227985e::Set<1,-1,-1>,struct cv::impl::A0xe227985e::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-763fcf770be4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimage2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:\\\\Users\\\\shant\\\\dataset\\\\stereo\\\\centre\\\\1399381445767267.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mk2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mundistorted_image2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintrinsic_matrix_undistorted_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcamera_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpts1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpts2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_keypoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mundistorted_image1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mundistorted_image2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-a0af9a7702ec>\u001b[0m in \u001b[0;36mget_keypoints\u001b[1;34m(image1, image2)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;31m# use sift keypoint to get the points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0msift\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mORB_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0mkp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdes1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[0mkp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdes2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0mdes1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdes1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.2) c:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0xe227985e::Set<1,-1,-1>,struct cv::impl::A0xe227985e::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n"
     ]
    }
   ],
   "source": [
    "camera_model = 'C:\\\\Users\\\\shant\\\\dataset\\\\model\\\\'\n",
    "image1 = 'C:\\\\Users\\\\shant\\\\dataset\\\\stereo\\\\centre\\\\1399381445704778.png'\n",
    "k1, undistorted_image1 = intrinsic_matrix_undistorted_image(image1,camera_model)\n",
    "image2 = 'C:\\\\Users\\\\shant\\\\dataset\\\\stereo\\\\centre\\\\1399381445767267.png'\n",
    "k2, undistorted_image2 = intrinsic_matrix_undistorted_image(image2,camera_model)\n",
    "pts1, pts2 = get_keypoints(undistorted_image1,undistorted_image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = []\n",
    "A.append(R1)\n",
    "A.append(R1)\n",
    "A = np.vstack(A)\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.40824829],\n",
       "        [-0.81649658],\n",
       "        [ 0.40824829]]), array([[-0.40824829],\n",
       "        [ 0.81649658],\n",
       "        [-0.40824829]]), array([[ 0.40824829],\n",
       "        [-0.81649658],\n",
       "        [ 0.40824829]]), array([[-0.40824829],\n",
       "        [ 0.81649658],\n",
       "        [-0.40824829]])]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = ExtractCameraPose(K)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
