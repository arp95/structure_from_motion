{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm to Follow for Performing Visual Odometry\n",
    "\n",
    "Feature Matching and Outlier rejection using RANSAC\n",
    "\n",
    "Estimating Fundamental Matrix\n",
    "\n",
    "Estimating Essential Matrix from Fundamental Matrix\n",
    "\n",
    "Estimate Camera Pose from Essential Matrix\n",
    "\n",
    "Check for Cheirality Condition using Triangulation\n",
    "\n",
    "Perspective-n-Point\n",
    "\n",
    "Bundle Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from ReadCameraModel import *\n",
    "from UndistortImage import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 241,
=======
   "execution_count": 165,
>>>>>>> d1dd6884311195231fdaeea3cd096667cbc973fa
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "\n",
    "camera_model = glob.glob('C:\\\\Users\\\\shant\\\\dataset\\\\model\\\\')\n",
    "data_files = glob.glob('C:\\\\Users\\\\shant\\\\dataset\\\\stereo\\\\centre\\\\')\n",
    "\n",
    "def intrinsic_matrix_undistorted_image(images,model_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    model_path: The path to the model files\n",
    "    images: The input image\n",
    "    \n",
    "    Outputs:\n",
    "    k_matrix: The intrinsic parameters\n",
    "    undistorted_image: The undistorted image\n",
    "    \"\"\"\n",
    "    image = cv2.imread(images)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BAYER_GR2BGR)\n",
    "    \n",
    "    fx, fy, cx, cy, G_camera_image, LUT = ReadCameraModel(model_path)\n",
    "    k_matrix = np.zeros((3,3))\n",
    "    k_matrix[0,0] = fx\n",
    "    k_matrix[0,2] = cx\n",
    "    k_matrix[1,1] = fy\n",
    "    k_matrix[1,2] = cy\n",
    "    k_matrix[2,2] = 1\n",
    "    \n",
    "    undistorted_image = UndistortImage(image, LUT)\n",
    "    \n",
    "    return (k_matrix, undistorted_image)\n",
    "\n",
    "# Estimating the Fundamental and Essential Matrix\n",
    "\n",
    "def FundamentalMatrix(input_points, output_correspondence, scaling):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    input_points: This is a Nx2 Matrix of (x,y) points\n",
    "    output_correspondance: This is a Nx2 Matrix of (x',y') points\n",
    "    scaling: The maximum of the input images width and height\n",
    "    \n",
    "    \"\"\"\n",
    "    # Normalize the input coordinates with the scaling factor\n",
    "    \n",
    "    pts1 = input_points / scaling\n",
    "    pts2 = output_correspondence / scaling\n",
    "    \n",
    "    # List of Fundamental Matrix\n",
    "    F_list = []\n",
    "    \n",
    "    # Transformation matrix for unnormalizing the fundamental matrix\n",
    "    T = np.array([[1/scaling,0,0],[0,1/scaling,0],[0,0,1]])\n",
    "    \n",
    "    # Construct the A matrix \n",
    "    first_row_A = np.array([[pts1[:,0][0]*pts2[:,0][0], pts1[:,0][0]*pts2[:,1][0], pts1[:,0][0], pts1[:,1][0]*pts2[:,0][0], pts1[:,1][0]*pts2[:,1][0], pts1[:,1][0], pts2[:,0][0], pts2[:,1][0], 1]])\n",
    "    second_row_A = np.array([[pts1[:,0][1]*pts2[:,0][1], pts1[:,0][1]*pts2[:,1][1], pts1[:,0][1], pts1[:,1][1]*pts2[:,0][1], pts1[:,1][1]*pts2[:,1][1], pts1[:,1][1], pts2[:,0][1], pts2[:,1][1], 1]])\n",
    "    third_row_A = np.array([[pts1[:,0][2]*pts2[:,0][2], pts1[:,0][2]*pts2[:,1][2], pts1[:,0][2], pts1[:,1][2]*pts2[:,0][2], pts1[:,1][2]*pts2[:,1][2], pts1[:,1][2], pts2[:,0][2], pts2[:,1][2], 1]]) \n",
    "    fourth_row_A = np.array([[pts1[:,0][3]*pts2[:,0][3], pts1[:,0][3]*pts2[:,1][3], pts1[:,0][3], pts1[:,1][3]*pts2[:,0][3], pts1[:,1][3]*pts2[:,1][3], pts1[:,1][3], pts2[:,0][3], pts2[:,1][3], 1]])\n",
    "    fifth_row_A = np.array([[pts1[:,0][4]*pts2[:,0][4], pts1[:,0][4]*pts2[:,1][4], pts1[:,0][4], pts1[:,1][4]*pts2[:,0][4], pts1[:,1][4]*pts2[:,1][4], pts1[:,1][4], pts2[:,0][4], pts2[:,1][4], 1]])\n",
    "    sixth_row_A = np.array([[pts1[:,0][5]*pts2[:,0][5], pts1[:,0][5]*pts2[:,1][5], pts1[:,0][5], pts1[:,1][5]*pts2[:,0][5], pts1[:,1][5]*pts2[:,1][5], pts1[:,1][5], pts2[:,0][5], pts2[:,1][5], 1]])\n",
    "    seventh_row_A = np.array([[pts1[:,0][6]*pts2[:,0][6], pts1[:,0][6]*pts2[:,1][6], pts1[:,0][6], pts1[:,1][6]*pts2[:,0][6], pts1[:,1][6]*pts2[:,1][6], pts1[:,1][6], pts2[:,0][6], pts2[:,1][6], 1]]) \n",
    "    eighth_row_A = np.array([[pts1[:,0][7]*pts2[:,0][7], pts1[:,0][7]*pts2[:,1][7], pts1[:,0][7], pts1[:,1][7]*pts2[:,0][7], pts1[:,1][7]*pts2[:,1][7], pts1[:,1][7], pts2[:,0][7], pts2[:,1][7], 1]])\n",
    "    \n",
    "    # Stack the rows to create the A matrix\n",
    "    A = np.vstack((first_row_A,second_row_A,third_row_A,fourth_row_A,fifth_row_A,sixth_row_A,seventh_row_A,eighth_row_A,np.ones(9)))\n",
    "    # Singular Value Decomposition\n",
    "    U, S, Vh = np.linalg.svd(A)\n",
    "    V = Vh.T\n",
    "    \n",
    "    # Constructing the fundamental matrix by taking the last column of the V matrix as it corresponds to the nullspace eigenvector\n",
    "    fundamental_matrix = V[:,-1]\n",
    "    fundamental_matrix = fundamental_matrix.reshape(3,3)\n",
    "    \n",
    "    # Enforcing Rank 2 constraint\n",
    "    U, sigma, Vh = np.linalg.svd(fundamental_matrix)\n",
    "    sigma[2] = 0\n",
    "    fundamental_matrix = np.matmul(U, np.matmul(np.diag(sigma), Vh))\n",
    "    \n",
    "    # Unnormalize the fundmental matrix\n",
    "    fundamental_matrix = np.matmul(np.matmul(T.T, fundamental_matrix), T)\n",
    "    \n",
    "    F_list.append(fundamental_matrix)\n",
    "    return F_list\n",
    "    \n",
    "def get_keypoints(image1, image2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    image1: The left image\n",
    "    image2: The right image\n",
    "    \n",
    "    Outputs:\n",
    "    left_correspondence:\n",
    "    right_correspondence:\n",
    "    \n",
    "    \"\"\"\n",
    "def FundamentalMatrixRansac(input_points, output_correspondence, scaling):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    input_points: This is a randomly sampled input point correspondence\n",
    "    output_correspondance: This is the output point correspondence\n",
    "    \n",
    "    Outputs:\n",
    "    fundamental_matrix: The refined fundamental matrix after performing RANSAC\n",
    "    \"\"\"\n",
    "    # Convert the correspondences into homogenous coordinates\n",
    "    pts1 = np.hstack(input_points, np.ones(input_points.shape[0],1))\n",
    "    pts2 = np.hstack(output_correspondence, np.ones(output_correspondence.shape[0], 1))\n",
    "    \n",
    "    # Number of iterations\n",
    "    iterations = 1000\n",
    "    \n",
    "    # The threshold error\n",
    "    epsilon = 0.01\n",
    "    \n",
    "    # The indices with value less than the error\n",
    "    best_indices = None\n",
    "    \n",
    "    # Best Fundamental Matrix\n",
    "    best_fundamental_matrix = None\n",
    "    \n",
    "    # Best Inliers\n",
    "    best_inliers = 0\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        rand_index = np.random.choice(input_points.shape[0], 8, False)\n",
    "        F = FundamentalMatrix(input_points[rand_index], output_correspondence[rand_index],scaling)\n",
    "        \n",
    "        for fundamental_matrix in F:\n",
    "            \n",
    "            # Print a List of indices\n",
    "            indices = np.where(np.abs(np.matmul(pts2, np.matmul(fundamental_matrix, pts.T))).diagonal() < epsilon)[0]\n",
    "            \n",
    "            if len(indices) > best_inliers:\n",
    "                \n",
    "                best_fundamental_matrix = fundamental_matrix\n",
    "                best_indices = indices\n",
    "                best_inliers = len(indices)\n",
<<<<<<< HEAD
    "\n",
    "# Compute the Essential Matrix\n",
=======
    "    \n",
>>>>>>> d1dd6884311195231fdaeea3cd096667cbc973fa
    "def EssentialMatrix(fundamental_matrix, calibration_matrix):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    fundamental_matrix: The fundamental matrix that gives the epipolar line on which an input point must lie\n",
    "    calibration_matrix: The K matrix responsible for projecting an object in camera coordinates to the image coordinate system\n",
    "    \n",
    "    Ouput:\n",
    "    essential_matrix: The essential matrix giving the relation between the 2 image points\n",
    "    \"\"\"\n",
    "    essential_matrix = np.matmul(calibration_matrix.T, np.matmul(fundamental_matrix,calibration_matrix))\n",
    "    U, sigma, Vh = np.linalg.svd(essential_matrix)\n",
    "    \n",
    "    sigma[0] = 1\n",
    "    sigma[1] = 1\n",
    "    sigma[2] = 0\n",
    "    \n",
    "    essential_matrix = np.matmul(U, np.matmul(np.diag(sigma), Vh))\n",
    "    \n",
    "    return essential_matrix\n",
    "\n",
<<<<<<< HEAD
    "# Get the Camera Poses(translation and rotation matrices)\n",
=======
>>>>>>> d1dd6884311195231fdaeea3cd096667cbc973fa
    "def ExtractCameraPose(essential_matrix):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    essential_matrix: The Essential Matrix\n",
    "    \n",
    "    Outputs:\n",
    "    Camera Poses\n",
    "    \"\"\"\n",
    "    \n",
    "    W = np.array([[0,-1,0],[1,0,0],[0,0,1]])\n",
    "    \n",
    "    # Perform the Singular Value Decomposition of the Essential Matrix\n",
    "    U, sigma, Vh = np.linalg.svd(essential_matrix)\n",
    "    \n",
    "    # Defining the 4 Camera Poses (c1,r1), (c2,r2), (c3,r3), (c4,r4)\n",
<<<<<<< HEAD
    "    c1 = U[:,2]\n",
    "    c2 = -U[:,2]\n",
    "    c3 = U[:,2]\n",
    "    c4 = -U[:,2]\n",
=======
    "    c1 = U[:,3]\n",
    "    c2 = -U[:,3]\n",
    "    c3 = U[:,3]\n",
    "    c4 = -U[:,3]\n",
>>>>>>> d1dd6884311195231fdaeea3cd096667cbc973fa
    "    r1 = np.dot(U, np.dot(W, Vh))\n",
    "    r2 = np.dot(U, np.dot(W, Vh))\n",
    "    r3 = np.dot(U, np.dot(np.transpose(W), Vh))\n",
    "    r4 = np.dot(U, np.dot(np.transpose(W), Vh))\n",
    "    \n",
    "    if np.linalg.det(r1) < 0:\n",
    "        c1 = -c1\n",
    "        r1 = -r1\n",
    "    if np.linalg.det(r2) < 0:\n",
    "        c2 = -c2\n",
    "        r2 = -r2\n",
    "    if np.linalg.det(r3) < 0:\n",
    "        c3 = -c3\n",
    "        r3 = -r3\n",
    "    if np.linalg.det(r4) < 0:\n",
    "        c4 = -c4\n",
    "        r4 = -r4\n",
    "    \n",
    "    # Reshape the translational matrices from 1x3 --> 3x1\n",
    "    c1 = c1.reshape(-1,1)\n",
    "    c2 = c2.reshape(-1,1)\n",
    "    c3 = c3.reshape(-1,1)\n",
    "    c4 = c4.reshape(-1,1)\n",
    "    \n",
<<<<<<< HEAD
    "    return [np.array(c1), np.array(c2), np.array(c3), np.array(c4)],[np.array(r1), np.array(r2), np.array(r3), np.array(r4)]\n",
    "\n",
    "# Triangulation Check for Cheirality \n",
    "def LinearTriangulation(K, C1, R1, C2, R2, pts1, pts2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    K: Camera Calibration Matrix\n",
    "    C1: The camera center for the first camera (3x1)\n",
    "    C2: The camera center for the second camera (3x1)\n",
    "    R1: The rotation matrix for the first camera (3x3)\n",
    "    R2: The rotation matrix for the second camera (3x3)\n",
=======
    "    return [[np.array(c1), np.array(c2), np.array(c3), np.array(c4)],[np.array(r1), np.array(r2), np.array(r3), np.array(r4)]]\n",
    "\n",
    "# Triangulation Check for Cheirality \n",
    "\n",
    "def LinearTriangulation(camera_pose1, camera_pose2, pts1, pts2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    camera_pose1: The camera pose for the first camera (3x4)\n",
    "    camera_pose2: The camera pose for the second camera (3x4)\n",
>>>>>>> d1dd6884311195231fdaeea3cd096667cbc973fa
    "    pts1: The points in left image whose correspondance needs to be found in the right image\n",
    "    pts2: The corresponding points in the right image\n",
    "    \n",
    "    Outputs:\n",
<<<<<<< HEAD
    "    P: x, y, z world coordinates (Nx3)\n",
    "    reprojection_error: The reprojection error from the world frame to the image frame\n",
    "    \"\"\"\n",
    "    \n",
    "    camera_pose1 = np.dot(np.dot(K,R1), np.concatenate((np.eye(3), -C1), axis = 1))\n",
    "    camera_pose2 = np.dot(np.dot(K,R2), np.concatenate((np.eye(3), -C2), axis = 1))\n",
    "    \n",
=======
    "    P: x, y, z world coordinates\n",
    "    reprojection_error: The reprojection error from the world frame to the image frame\n",
    "    \"\"\"\n",
>>>>>>> d1dd6884311195231fdaeea3cd096667cbc973fa
    "    P = []\n",
    "    reprojection_error = 0\n",
    "    \n",
    "    # Constructing the A matrix\n",
    "    for i in range(pts1.shape[0]):\n",
    "        \n",
    "        A =  [pts1[i, 0] * camera_pose1[2, :] - camera_pose1[0, :],\n",
    "              pts1[i, 1] * camera_pose1[2, :] - camera_pose1[1, :],\n",
    "              pts2[i, 0] * camera_pose2[2, :] - camera_pose2[0, :],\n",
    "              pts2[i, 1] * camera_pose2[2, :] - camera_pose2[1, :]]\n",
    "        \n",
    "        \n",
    "        # Perform the singular value decomposition of the A matrix\n",
    "        U, sigma, Vh = np.linalg.svd(A)\n",
    "        \n",
    "        # Extract the last row corresponding the nullspace of the linear equation\n",
    "        p = Vh[-1,:]\n",
    "        \n",
    "        # Convert to homogenous coordinates\n",
    "        w = p/p[3]\n",
    "        \n",
    "        # X,Y,Z co-ordinates in the world frame\n",
    "        P.append(w[:3])\n",
    "        \n",
    "        # Checking the Reprojection Error\n",
    "        projection1 = np.dot(camera_pose1, w)\n",
    "        projection2 = np.dot(camera_pose2, w)\n",
    "        \n",
    "        # Calculating the Reprojection error\n",
<<<<<<< HEAD
    "        # Computing the eucledian distance between the projected image and the object in the world frame\n",
    "        reprojection_error += np.linalg.norm(projection1[:2]/projection1[-1] - pts1[i])**2 + np.linalg.norm(projection2[:2]/projection2[-1] - pts2[i])**2\n",
    "        \n",
    "    return np.asarray(P), reprojection_error\n",
    "\n",
    "# Non Linear Triangulation\n",
    "def NonLinearTriangulation(K, C1, R1, C2, R2, pts1, pts2, X0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    K: The camera calibration matrix\n",
    "    C1 and R1: The first camera pose\n",
    "    C2 and R2: The second camera pose\n",
    "    pts1 and pts2: The Nx2 point correspondence\n",
    "    X0: The triangulated 3D Points\n",
    "    \n",
    "    Outputs:\n",
    "    X: Nx3 Matrix that represents the triangulated points\n",
    "    \"\"\"\n",
    "    # The camera poses/ Projection Matrices\n",
    "    camera_pose1 = np.dot(np.dot(K,R1), np.concatenate((np.eye(3), -C1), axis = 1))\n",
    "    camera_pose2 = np.dot(np.dot(K,R2), np.concatenate((np.eye(3), -C2), axis = 1))\n",
    "    \n",
    "    \n",
    "\n",
    "# Check whether the point is infront of the camera pose or not\n",
    "def DisambiguateCameraPose(Cset, Rset, Xset):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    Cset: 4 Camera Rotation Configurations\n",
    "    Rset: 4 Camera rotation configurations\n",
    "    Xset: 4 set of traingulated camera points\n",
    "    \n",
    "    Output:\n",
    "    C,R: The best Camera Pose\n",
    "    \n",
    "    \"\"\"\n",
    "    best = 0\n",
    "    \n",
    "    for i in range(4):\n",
    "        \n",
    "        # Loop through each correspondence\n",
    "        counter = 0\n",
    "        for j in range(len(Xset[i])):\n",
    "            \n",
    "            # Cheirality Condition\n",
    "            if(Rset[i][2,:]*(Xset[i][j,:] - Cset[i]) > 0):\n",
    "                \n",
    "                n = n + 1\n",
    "                \n",
    "        if n > best:\n",
    "            \n",
    "            C = Cset[i]\n",
    "            R = Rset[i]\n",
    "            X0 = Xset[i]\n",
    "            best = n\n",
    "    \n",
    "    return C, R, X0"
=======
    "        reprojection_error += np.linalg.norm(projection1[:2]/projection1[-1] - pts1[i])**2 + np.linalg.norm(projection2[:2]/projection[-1] - pts2[i])**2\n",
    "        \n",
    "    return np.asarray(P), reprojection_error\n"
>>>>>>> d1dd6884311195231fdaeea3cd096667cbc973fa
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 270,
=======
   "execution_count": 195,
>>>>>>> d1dd6884311195231fdaeea3cd096667cbc973fa
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "4"
      ]
     },
     "execution_count": 270,
=======
       "array([8, 9])"
      ]
     },
     "execution_count": 195,
>>>>>>> d1dd6884311195231fdaeea3cd096667cbc973fa
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "A = np.array([[1,2,3],[4,5,6],[8,9,10],[11,12,13]])\n",
    "x = A[:,:-1]\n",
    "x[2,:]\n",
    "len(A)"
=======
    "A = np.array([[1,2],[4,5],[8,9],[12,13]])\n",
    "A[2]"
>>>>>>> d1dd6884311195231fdaeea3cd096667cbc973fa
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 262,
=======
   "execution_count": 194,
>>>>>>> d1dd6884311195231fdaeea3cd096667cbc973fa
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "array([[  30.,   36.,   42., -228.],\n",
       "       [  66.,   81.,   96., -516.],\n",
       "       [ 114.,  141.,  168., -900.]])"
      ]
     },
     "execution_count": 262,
=======
       "array([4])"
      ]
     },
     "execution_count": 194,
>>>>>>> d1dd6884311195231fdaeea3cd096667cbc973fa
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "K = np.array([[1,2,3],[4,5,6],[8,9,10]])\n",
    "R = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "x = np.array([[1],[2],[3]])\n",
    "y = np.dot(K,R)\n",
    "z = np.dot(y, np.concatenate((np.eye(3),x), axis = 1))\n",
    "#z\n",
    "\n",
    "np.dot(np.dot(K,R),np.concatenate((np.eye(3),-x), axis = 1))"
=======
    "x = np.array([[1],[2],[3],[4]])\n",
    "x[-1]"
>>>>>>> d1dd6884311195231fdaeea3cd096667cbc973fa
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 8],\n",
       "       [4, 5],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[[2,1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "A = np.array([[1,8,1,2],[2,9,1,2],[3,10,1,56]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,2,3]])\n",
    "A.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 10,  1, 56])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[2,:]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7109468398851384"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,8,1],[2,9,1],[3,10,1]])\n",
    "Cset, Rset = ExtractCameraPose(A)\n",
    "Rset[1][1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42498222, -0.69758116, -0.57686276])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rset[1][2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shant\\anaconda3\\envs\\env\\lib\\site-packages\\ipykernel_launcher.py:256: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2,3,4],[4,5,6,7],[8,9,10,12]])\n",
    "B = np.array([[13,14,15,16],[17,18,19,20],[21,22,23,24]])\n",
    "pts1 = np.array([[1,2],[3,4],[5,6],[7,8]])\n",
    "pts2 = np.array([[9,10],[11,12],[13,14],[15,16]])\n",
    "x,y = LinearTriangulation(A,B,pts1,pts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.16872170e+13, -4.33744340e+13,  2.16872170e+13],\n",
       "       [ 1.02083899e+13, -2.04167798e+13,  1.02083899e+13],\n",
       "       [-3.02712967e+13,  6.05425934e+13, -3.02712967e+13],\n",
       "       [ 1.45380435e+13, -2.90760870e+13,  1.45380435e+13]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> d1dd6884311195231fdaeea3cd096667cbc973fa
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
